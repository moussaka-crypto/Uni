{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbgYWScQSQ4-"
      },
      "source": [
        "Dieses Notebook zeigt, wie man ein spezielles Rekurrentes Neuronales Netz (LSTM) zur Vorhersage von Energieverbrauchsdaten trainieren kann. \n",
        "Hierfür werden die Bibliotheken keras, sowie sci-kit learn verwendet.\n",
        "Das Notebook orientiert sich an folgendem Tutorial: https://www.elab2go.de/demo-py5/ (Autoren: Prof. Dr. Eva Maria Kiss, B. Sc. Franc Willy Pouhela, M. Sc. Anke Welz)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKCtHqefSPFj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import math\n",
        "\n",
        "# matplotlib und seaborn zum Plotten\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# scikit-learn für Überwachtes Lernen\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import max_error\n",
        "\n",
        "# keras für Neuronale Netze\n",
        "import tensorflow as tf \n",
        "import keras as keras\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, LSTM, Dropout \n",
        "from keras.utils.vis_utils import plot_model \n",
        "from keras import activations\n",
        "\n",
        "# Für das Darstellen von Bildern im SVG-Format\n",
        "import graphviz as gv\n",
        "import pydot\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmm976BpAi1i"
      },
      "outputs": [],
      "source": [
        "# Daten einlesen\n",
        "data = pd.read_csv('https://www.elab2go.de/demo-py5/opsd_2016-2019.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXwyyg9jCTtF"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtUkldNHCU7B"
      },
      "outputs": [],
      "source": [
        "data.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aufgabe 1: Datenvorbereitung\n",
        " \n",
        "\n",
        "* a) Überprüfen Sie, ob in dem Datensatz NaN enthalten sind. Falls ja, überlegen Sie sich, wie Sie damit am besten umgehen.\n",
        "*   b) Ist es sinnvoll, mit allen Merkmalen fortzufahren? Was müssen Sie tun um diese Frage beantworten zu können?\n",
        "*   c) Bringen Sie die Spalte \"Datum\" in ein geeignetes Format und indizieren Sie das dataframe mit dieser Spalte \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_ruAL4TjMF-m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LprFtFGuCYQL"
      },
      "outputs": [],
      "source": [
        "# Frage 1 a) Überprüfen auf NaN\n",
        "\n",
        "# ....."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Frage 1 b)\n",
        "\n",
        "# .....\n",
        "\n"
      ],
      "metadata": {
        "id": "kCrYJQHBNT2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ..."
      ],
      "metadata": {
        "id": "Q9IjK4isNOi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYYRMjO6C6dY"
      },
      "outputs": [],
      "source": [
        "# Frage 1 c)\n",
        "\n",
        "# ....."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhkcjBBsCsT1"
      },
      "outputs": [],
      "source": [
        "# Plotten des Stromverbrauchs. Der Stromverbrauch soll später mithilfe des Neuronalen Netzes vorhergesagt werden.\n",
        "\n",
        "sns.set(rc={'figure.figsize':(12, 4)})\n",
        "sns.set_color_codes('bright')\n",
        "\n",
        "ax = data['Verbrauch'].plot(linewidth=1, color='b', marker = '.')\n",
        "ax.set_title('Täglicher Stromverbrauch')\n",
        "ax.set_xlabel('Datum');\n",
        "ax.set_ylabel('GwH');"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aufgabe 2\n",
        "\n",
        "Im nächsten Codeblock werden zeitlich versetzte Merkmale (sogenannte Lagged Features) erzeugt.  \n",
        "\n",
        "*   a) Was macht dabei die Funktion shift()? Schauen Sie in der pandas Dokumentation nach!\n",
        "*   b) Was macht die Funktion concat()? Schauen Sie auch das in der pandas Dokumentation nach!\n",
        "*   c) Führen Sie die untenstehende Zelle aus und Lassen Sie sich anschließend die ersten 10 Zeilen des neu erzeugten dataframes ausgeben. Hat das Erzeugen der zeitlich versetzten Merkmale erfolgreich funktioniert?\n",
        "\n"
      ],
      "metadata": {
        "id": "L-y0FKomOETF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Antworten\n",
        "\n",
        "\n",
        "\n",
        "*   a) ....\n",
        "*   b) ....\n",
        "*   c) .....\n",
        "\n"
      ],
      "metadata": {
        "id": "iXixVLD8UU6I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38nuB_e8Fgyd"
      },
      "outputs": [],
      "source": [
        "# Erzeuge zeitlich versetzte Merkmale (lagged features)\n",
        "\n",
        "consumption = pd.DataFrame(data['Verbrauch'])\n",
        "\n",
        "data = pd.concat([consumption.shift(7),consumption.shift(6), consumption.shift(5), consumption.shift(4), \n",
        "                  consumption.shift(3), consumption.shift(2), consumption.shift(1), data[['Verbrauch']]], axis=1)\n",
        "\n",
        "data.columns =  ['t-7', 't-6', 't-5', 't-4', 't-3', 't-2', 't-1', 'Verbrauch']\n",
        "\n",
        "data.head()\n",
        "\n",
        "data.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnvY2JYtTNXn"
      },
      "outputs": [],
      "source": [
        "data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cITs1ZxLCzXQ"
      },
      "outputs": [],
      "source": [
        "# Daten in Trainings- und Testset aufspalten\n",
        "\n",
        "TEST_SPLIT = 0.1 \n",
        "#data = data.drop(columns = ['Wind', 'Solar'])\n",
        "train_size = int(len(data) * (1-test_split))\n",
        "test_size = len(data) - train_size\n",
        "train = data.iloc[0:train_size]\n",
        "test = data.iloc[train_size:len(data)]\n",
        "print(\"Trainingsdaten:\") \n",
        "print(train.head())\n",
        "print(train.tail())\n",
        "print(\"Testdaten:\") \n",
        "print(test.head())\n",
        "print(test.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLkdRtBBDOOE"
      },
      "outputs": [],
      "source": [
        "# Daten auf den Wertebereich [0, 1] skalieren\n",
        "\n",
        "scaler = MinMaxScaler(feature_range = (0,1))\n",
        "\n",
        "train_s = scaler.fit_transform(np.array(train))\n",
        "test_s = scaler.fit_transform(np.array(test))\n",
        "\n",
        "print(\"Trainingsdaten (unskaliert)\\n\")\n",
        "print(train.head(3))\n",
        "print(\"\\nTrainingsdaten (skaliert)\\n\")\n",
        "train_s = pd.DataFrame( train_s , columns = data.columns)\n",
        "train_s = train_s.set_index(train.index )\n",
        "print(train_s.head(3))\n",
        "\n",
        "print(\"Testdaten (unskaliert)\\n\")\n",
        "print(test.head(3))\n",
        "print(\"\\nTestdaten (skaliert)\\n\")\n",
        "test_s = pd.DataFrame( test_s , columns = data.columns)\n",
        "test_s = test_s.set_index(test.index )\n",
        "print(test_s.head(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjYQ-fbzUvdu"
      },
      "outputs": [],
      "source": [
        "# In Merkmale und Label aufteilen\n",
        "\n",
        "X_train = train_s.drop(columns = ['Verbrauch'])\n",
        "y_train = pd.DataFrame(train_s['Verbrauch'])\n",
        "\n",
        "print(X_train.head())\n",
        "print(y_train.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBpV9MC4EBSK"
      },
      "outputs": [],
      "source": [
        "TIMESTEPS = 7 # Länge eines gleitenden Zeitfensters\n",
        "UNITS = 10 # Ausgabedimension einer einzelnen LSTM-Schicht\n",
        "N_LAYER = 2 # Anzahl an LSTM-Schichten\n",
        "\n",
        "# Initialisiere ein sequentielles Modell (Modell mit mehreren Schichten)\n",
        "model = Sequential(name='sequential') \n",
        "\n",
        "#Füge so viele Schichten hinzu, wie in N_LAYER angegeben\n",
        "for i in range(N_LAYER):\n",
        "\n",
        "  lstm_layer = LSTM(units = UNITS, # Dimension der Ausgabe\n",
        "                    input_shape=(TIMESTEPS,1), # Dimension der Eingabe (1. Dimension entspricht Anzahl Zeitschritte, 2. Dimension:  1, da nur ein Merkmal = Verbrauch über die Zeit betrachtet wird (univariates Problem) )\n",
        "                    return_sequences=True, # wir wollen die gesamte Ausgabesequenz der jeweiligen LSTM-Schicht in die nächste LSTM-Schicht weitergeben können\n",
        "                    name = 'lstm_' + str(i+1)) # Schichten werden mit \"lstm_\" + Schichtnummer benannt\n",
        "                   \n",
        "  model.add(lstm_layer) # Schicht dem Modell hinzufügen\n",
        "\n",
        "\n",
        "# weitere LSTM Schicht hinzufügen, bei der nur die letzte Ausgabe (und nicht wie oben die ganze Sequenz) in die nächste Schicht weitergegeben wird\n",
        "model.add(LSTM(units = UNITS, input_shape=(TIMESTEPS,1), name = 'lstm_' + str(N_LAYER+1)))\n",
        "\n",
        "# Lineares Layer mit ReLU-Aktivierungsfunktion\n",
        "model.add(Dense(units = 1, name='dense_1'))#, activation=activations.tanh))\n",
        "\n",
        "# Konfiguriere das Modell für die Trainingsphase \n",
        "\n",
        "# Angeben welcher Optimierer verwendet werden soll\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "# über welche Verlustfunktion optimiert werden soll \n",
        "# und wie die Performance des Modells gemessen werden soll (hier werden Verlustfunktion und Performancemetrik gleich gewählt, muss aber nicht so sein))\n",
        "model.compile(optimizer = opt, loss = \"mse\", metrics=['mean_squared_error'])\n",
        "\n",
        "# Zusammenfassung und Visualisierung des Modells\n",
        "model.summary()\n",
        "plot_model(model, show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aufgabe 3\n",
        "\n",
        "Welchen Parameter der obigen Codezelle müssten Sie verändern, um 3 LSTM Schichten zu bekommen?"
      ],
      "metadata": {
        "id": "KrKru1jmRN3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aufgabe 4\n",
        "\n",
        "Das Neuronale Netz wird in der unten stehenden Codezelle trainiert. Führen Sie den Code aus. \n",
        "Nach wie vielen Epochen wird das Training auf jeden Fall stoppen?"
      ],
      "metadata": {
        "id": "BRrNMG51SAEt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fk5LqeA9EFMd"
      },
      "outputs": [],
      "source": [
        "# Modell trainieren\n",
        "\n",
        "# Erstelle Callback für Stop-Kriterium\n",
        "from keras.callbacks import EarlyStopping, CSVLogger\n",
        "cb_stop = EarlyStopping(monitor='val_loss', mode='min', \n",
        "                        verbose=1, patience=200)\n",
        "log_file = 'demo-py5-log.csv'\n",
        "cb_logger = CSVLogger(log_file, append=False, separator=';')\n",
        "\n",
        "# X_train erhält eine zusätzliche Dimension und wird dreidimensional\n",
        "X_train = np.array(X_train)\n",
        "X_train = np.reshape(X_train, \n",
        "                     (X_train.shape[0], X_train.shape[1], 1))\n",
        "\n",
        "print(X_train.shape)\n",
        "\n",
        "# Trainiere das Modell mit Hilfe der Funktion fit()\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 1000\n",
        "history = model.fit(X_train, y_train, \n",
        "                    epochs=EPOCHS, batch_size=BATCH_SIZE, \n",
        "                    validation_split=TEST_SPLIT, verbose=2, \n",
        "                    callbacks=[cb_logger, cb_stop])\n",
        "\n",
        "# Speichere das Modell im Format HDF5\n",
        "model.save(\"model_adam.h5\")\n",
        "\n",
        "print(\"History\");print(history.history.keys());"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aufgabe 5\n",
        "\n",
        "Im untenstehenden Codeblock wird der Trainingsfortschritt geplottet. Wie beurteilen Sie ihn?"
      ],
      "metadata": {
        "id": "BQA7oBZ6TP6X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96-yfi5QmDBC"
      },
      "outputs": [],
      "source": [
        "# Trainingsfortschritt plotten\n",
        "\n",
        "plt.plot(history.history['mean_squared_error'], label='MSE (Trainingsdaten)')\n",
        "plt.plot(history.history['val_mean_squared_error'], label='MSE (Testdaten)')\n",
        "\n",
        "plt.title('Training: Entwicklung des Fehlers')\n",
        "plt.ylabel('MSE-Fehler')\n",
        "plt.xlabel('Epochen')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vl7Kw0kEmNsE"
      },
      "outputs": [],
      "source": [
        "# Testdaten in Merkmale X und Label y aufteilen\n",
        "\n",
        "X_test = test_s.drop(columns = ['Verbrauch'])\n",
        "y_test = pd.DataFrame(test_s['Verbrauch'])\n",
        "\n",
        "# Vorhersage für skalierte Testdaten\n",
        "X_test = np.array(X_test)\n",
        "X_test_input = np.reshape(X_test, \n",
        "        (X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "y_test = np.array(y_test)\n",
        "#y_test = np.reshape(y_test, \n",
        "        # (y_test.shape[0],  1))\n",
        "y_pred = model.predict(X_test_input)\n",
        "\n",
        "pred = np.concatenate((X_test, y_pred), axis=1)\n",
        "\n",
        "# Reskaliere die Daten\n",
        "test_rs = pd.DataFrame(scaler.inverse_transform(test_s), columns = test_s.columns)\n",
        "pred_rs = pd.DataFrame(scaler.inverse_transform(pred), columns = test_s.columns)\n",
        "\n",
        "y_test = test_rs['Verbrauch']\n",
        "y_pred = pred_rs['Verbrauch']\n",
        "\n",
        "# Berechne RMSE der Validierungsdaten\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.round(np.sqrt(mse))\n",
        "print(\"Validierungs-Fehler:\")\n",
        "print(\"\\nMSE:\\n %.2lf\" % (mse))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axF8FLI5qxkt"
      },
      "outputs": [],
      "source": [
        "def rel_error(df, col1, col2):\n",
        "    df['Error (%)'] = (df[col1] - df[col2]) / df[col1]  * 100\n",
        "    df['Error (%)'] = df['Error (%)'].abs()\n",
        "    return df['Error (%)']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HN0q4AodxpPj"
      },
      "outputs": [],
      "source": [
        "# Hilfsfunktion error_table erzeugt Fehlertabelle\n",
        "def error_table(df1, df2, col1, col2, idx):\n",
        "    cols = [df1, df2]\n",
        "    headers = [col1, col2]\n",
        "    # Erzeuge pred aus y_test und y_pred mit Index idx\n",
        "    pred = pd.concat(cols, axis=1, keys=headers) \n",
        "    pred.set_index(idx, inplace=True)\n",
        "    # Füge Fehler-Spalten hinzu\n",
        "    pred['Error'] = np.abs(pred['y_test'] - pred['y_pred'])\n",
        "    pred['Error(%)'] = rel_error(pred, 'y_test', 'y_pred')\n",
        "    pred = pred.astype(float).round(1)\n",
        "    # Füge RMSE hinzu\n",
        "    mse = mean_squared_error(df1, df2)\n",
        "    rmse = np.round(np.sqrt(mse))\n",
        "    pred.index.name = \"RMSE: \" + str(rmse)\n",
        "    return pred\n",
        "\n",
        "# Erzeuge Fehlertabelle für Validierung und gebe sie aus\n",
        "idx = test.index;\n",
        "pred = error_table(pd.DataFrame(y_test), pd.DataFrame(y_pred), 'y_test', 'y_pred', idx)\n",
        "\n",
        "pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hf8vmdiCmWPg"
      },
      "outputs": [],
      "source": [
        "pred['Error (%)'].min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBvPJvxdmZ9N"
      },
      "outputs": [],
      "source": [
        "pred['Error (%)'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTPeFBiX-bga"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "HandsOnPython_06_NeuronalesNetz.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_ruAL4TjMF-m",
        "KrKru1jmRN3G"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}