{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP5lilNxPUXd"
      },
      "source": [
        "### Erstellen eines Prognosemodells für den Energieverbrauch\n",
        "\n",
        "\n",
        "Dieses Notebook zeigt\n",
        "- wie man mithilfe eines Entscheidungsbaums ein Vorhersagemodell für den Energieverbrauch erstellen kann\n",
        "- wie man die Modell-Performance bewerten kann\n",
        "- wie man die Modell-Performance optimieren kann (Hyperparameteroptimierung)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzf7QuIEPUXr"
      },
      "outputs": [],
      "source": [
        "### Bibliotheken einbinden\n",
        "\n",
        "## Datenanalyse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "## Plotten\n",
        "import matplotlib.pyplot as plt\n",
        "# zeige Plots in Zellen des Notebooks an\n",
        "%matplotlib inline \n",
        "import seaborn as sns\n",
        "# setze seaborn style defaults und Default-Wert für Plotgröße\n",
        "sns.set(rc={'figure.figsize':(20, 10)}) \n",
        "\n",
        "## Maschinelles Lernen\n",
        "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
        "from sklearn.tree import export_text\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive mounten\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "MaPKqauxQCbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnbMA2yDPUXw"
      },
      "source": [
        "## Aufgabe 1\n",
        "Lesen Sie den Datensatz Energieverbrauch.csv ein und geben Sie sich die ersten Spalten aus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvHjZMUaPUXy"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/Energieverbrauch.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLJIhG0WPUX1"
      },
      "source": [
        "## Aufgabe 2\n",
        "- Sie wollen ein Vorhersagemodell für den Energiebedarf erstellen.\n",
        "- Indizieren Sie dazu zunächst das Dataframe mit dem Zeitstempel. \n",
        "- Vergessen Sie dabei nicht, das Datenformat der Spalte Date falls nötig zu ändern"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiKgkkpwPUX3"
      },
      "outputs": [],
      "source": [
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "data.set_index('Date', inplace=True)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzQcBr3LPUX5"
      },
      "source": [
        "## Aufgabe 3\n",
        "- Für das Vorhersagemodell wollen Sie folgende Merkmale heranziehen: \n",
        "    Jahr, Monat, Wochentag (0,1,2,3...,6 für Mo-So)\n",
        "- Solche zeitlichen Merkmale können Sie ganz leicht mithilfe des Zeitstempel-Index generieren. \n",
        "- Für den Wochentag wurde das unten beispielhaft schon durchgeführt. \n",
        "- Fügen Sie auf ähnliche Weise zwei weitere Spalten mit den Merkmalen Jahr und Monat ein. Hinweis: Verwenden Sie dazu die Attribute year und month des index.\n",
        "- Geben Sie sich Teile des Dataframes aus und inspizieren Sie die neu hinzugefügten Merkmale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TS5XTXrJPUX7"
      },
      "outputs": [],
      "source": [
        "data['Weekday'] = data.index.weekday\n",
        "\n",
        "# Das hier noch anpassen\n",
        "#data['Year'] = data.index. ...\n",
        "#data['Month'] = data.index. ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkT4nDocPUX9"
      },
      "source": [
        "## Aufgabe 4\n",
        "- Weiterhin wollen Sie das Merkmal Wochenende 0/1 generieren. \n",
        "- Wie das funktioniert, sieht man in der unteren Zelle.\n",
        "- Gehen Sie den Code durch und versuchen Sie zu verstehen, was passiert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVTlB-o1PUX_"
      },
      "outputs": [],
      "source": [
        "data['Weekend'] = [0 if x < 5 else 1 for x in data.index.weekday]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iu3ZoaKbPUYB"
      },
      "source": [
        "## Aufgabe 5\n",
        "- Unten kommt eine Zelle mit einer Hilfsfunktion. Sie müssen die Zelle einfach nur ausführen. Die Funktion an sich müssen Sie nicht verändern. \n",
        "- Versuchen Sie zu verstehen, was passiert. Was macht die Hilfsfunktion?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antwort: ....."
      ],
      "metadata": {
        "id": "seDbB9JrRYei"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dje3PbgyPUYD"
      },
      "outputs": [],
      "source": [
        "# Hilfsfunktion\n",
        "def generate_sets(df): \n",
        "    \n",
        "    # Spalte df auf in Trainings-, Validierungs- und Testmenge in den Anteilen 60%, 20%, 20%\n",
        "    df_train, df_validate, df_test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])        \n",
        "        \n",
        "    # Auswahl der Label durch Auswahl der entsprechenden Spalten                 \n",
        "    y_train = df_train['Consumption']\n",
        "    y_validate = df_validate['Consumption']\n",
        "    y_test = df_test['Consumption']\n",
        "        \n",
        "    # Merkmale nicht in des Modell einbeziehen und somit die jeweiligen Spalten aus dem Datensatz entfernen\n",
        "    X_train = df_train.drop(['Consumption','Year'], axis=1)\n",
        "    X_validate = df_validate.drop(['Consumption','Year'], axis=1)\n",
        "    X_test = df_test.drop(['Consumption','Year'], axis=1)                                                                          \n",
        "    \n",
        "    return X_train, y_train, X_validate, y_validate, X_test, y_test\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1u1G44aPUYE"
      },
      "source": [
        "## Aufgabe 6\n",
        "- Oben in der Hilfsfunktion wird das Merkmal 'Year' aus den Datensätzen entfernt und nicht in das Modell einbezogen. Warum macht das Sinn?\n",
        "- Weiterhin wird aus X_train/validate/test die Spalte \"Consumption\" gelöscht. Wieso macht das Sinn?\n",
        "- Wozu braucht man Trainings-, Validierungs- und Testmenge?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antwort: ...."
      ],
      "metadata": {
        "id": "VjaNopoSRctq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0i_TEQoPUYF"
      },
      "outputs": [],
      "source": [
        "# Datensatz aufteilen in Trainings-, Validierungs- und Testmenge mit der Hilfsfunktion:\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = generate_sets(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odcd6Ap8PUYH"
      },
      "source": [
        "## Aufgabe 7\n",
        "- Es folgt eine Hilfsfunktion zum Trainieren eines Entscheidungsbaum und der graphischen Ausgabe des trainierten Baumes.\n",
        "- Auch an dieser Funktion müssen Sie nichts ändern.\n",
        "- Vielleicht verstehen Sie Teile der Funktion?\n",
        "- Schauen Sie sich an, wie man Funktionen zum leichteren Verständnis mittels ''' ''' kommentieren kann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8sokImMPUYH"
      },
      "outputs": [],
      "source": [
        "# Hilfsfunktion 2\n",
        "def train_decision_tree(X_train, y_train, min_samples_split = 2, min_samples_leaf = 1, output=False):\n",
        "    '''\n",
        "    Hilfsfunktion zum Trainieren eines Entscheidungsbaumes auf einer Trainingsmenge.\n",
        "    \n",
        "    Inputs: \n",
        "    X_train (df): Dataframe mit den Merkmalsvektoren der Trainingsmenge\n",
        "    y_train (df): Dataframe mit den Labeln der Trainingsmenge\n",
        "    min_samples_split (float oder int): wenn float, prozentualer Mindestanteil an Samples in jedem Split,\n",
        "                                        wenn int, Mindestanzahl Samples in jedem Split\n",
        "    min_samples_split (float oder int): wenn float, prozentualer Mindestanteil an Samples in jedem Blatt des Entscheidungsbaumes,\n",
        "                                        wenn int, Mindestanzahl Samples in jedem Blatt\n",
        "    output (bool): ob eine Ausgabe erzeugt werden soll (Die Ausgabe enthält die Regeln des Entscheidungsbaumes und eine graphische \n",
        "                   Darstellung des Entscheidungsbaumes)\n",
        "                   \n",
        "    Outputs:\n",
        "    dtr: ein auf der Trainingsmenge trainierter Entscheidungsbaum, der nachfolgend zur Prognose verwendet werden kann          \n",
        "    '''\n",
        "    \n",
        "    # Spaltennamen (=Namen der Merkmale) für später speichern\n",
        "    feature_names = list(X_train.columns)\n",
        "    \n",
        "    # Dataframes in numpy arrays konvertieren, da der Entscheidungsbaum das als Input benötigt\n",
        "    X_train = np.array(X_train)\n",
        "    y_train = np.array(y_train)\n",
        "    \n",
        "    #Entscheidungsbaum mit bestimmten Hyperparametern (min_samples_splkit und min_samples_leaf intialisieren)\n",
        "    dtr = DecisionTreeRegressor(random_state = 0, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
        "    \n",
        "    # Entscheidungsbaum trainieren\n",
        "    dtr.fit(X_train, y_train)\n",
        "    \n",
        "    # Optionale Ausgabe generieren\n",
        "    if output:\n",
        "        \n",
        "        rules = export_text(dtr, feature_names = feature_names)\n",
        "        print(rules)\n",
        "        print('Folgende Merkmale waren verfügbar:', feature_names)\n",
        "        \n",
        "        with plt.style.context('classic'):\n",
        "            plt.figure(figsize=(20,10))\n",
        "            tree.plot_tree(dtr, filled=True, impurity=True, rounded=True, feature_names=feature_names)\n",
        "    \n",
        "    return dtr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I5jnNDzPUYJ"
      },
      "source": [
        "### Aufgabe 8:\n",
        "- Als nächstes wollen wir einen Entscheidungsbaum auf dem Trainingsdatensatz trainieren. \n",
        "- Dazu wird die Hilfsfunktion train_decision_tree herangezogen. \n",
        "- Diese enthält die Parameter min_samples_split und min_samples_leaf\n",
        "- Was bedeuten diese Parameter? Versuchen Sie dies mithilfe der Dokumentation zu klären:  \n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
        "- Was passiert wenn Sie diese Parameter verändern?\n",
        "- Führen Sie die Funktion in der untenstehenden Zelle mehrfach aus und variieren Sie dabei z.B. min_samples_split zwischen 2 und 2000. Probieren Sie mindestens 10 verschiedene Werte in diesem Bereich aus und betrachten den entstehenden Entscheidungsbaum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1SIfLHVPUYK"
      },
      "outputs": [],
      "source": [
        "# Datensatz aufteilen in Trainings-, Validierungs- und Testmenge mit Hilfsfunktion generate_sets\n",
        "trained_decision_tree = train_decision_tree(X_train, y_train, min_samples_split = 900, min_samples_leaf = 1, output=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxGTNod4PUYL"
      },
      "source": [
        "- Es folgt eine weitere Hilfsfunktion zur Vorhersage des Energieverbrauchs mithilfe des zuvor trainierten Entscheidungsbaums\n",
        "- Auch an dieser Funktion müssen Sie nichts ändern und wir sprechen sie gemeinsam durch.\n",
        "- Wichtig: mit dieser Funktion kann man testen, wie gut die Vorhersage auf der Validierungsmenge funktioniert, siehe Aufgabe 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hgk2VD87PUYM"
      },
      "outputs": [],
      "source": [
        "# Hilfsfunktion 3\n",
        "def predict_with_decision_tree(dtr, X_val, y_val, output=True):\n",
        "    '''\n",
        "    Hilfsfunktion zur Erstellung einer Vorhersage auf Basis eines trainierten Entscheidungsbaumes und zur Ausgabe der Gütemaße.\n",
        "    \n",
        "    Inputs: \n",
        "    dtr: ein zuvor auf einer Trainingsmenge trainierter Entscheidungsbaum, der zur Prognose verwendet werden kann  \n",
        "    X_val (df): Dataframe mit den Merkmalsvektoren der Validierungsmenge\n",
        "    y_val (df): Dataframe mit den Labeln der Validierungsmenge\n",
        "    output (bool): ob eine print-Ausgabe erzeugt werden soll (enthält Gütemaße), standardmäßig auf True.\n",
        "   \n",
        "    Outputs:\n",
        "    y_pred (np.array): Vorhersage des Entscheidungsbaumes für die Merkmalsvektoren der Validierungsmenge   \n",
        "    metrics_dict (dict): Dictionary mit den Metriken zur Bewertung der Vorhersagegüte\n",
        "    '''  \n",
        "    \n",
        "    # Vorhersage für Validierungsmenge mit Entscheidungsbaum generieren\n",
        "    y_pred = dtr.predict(X_val)\n",
        "    \n",
        "    ## Metriken zur Bewertung der Vorhersagegüte berechnen\n",
        "    # Absoluten Fehler berechnen: Betrag der Differenz zwischen Vorhersage und den tatsächlichen Label der Validierungsmenge\n",
        "    abs_errors = abs(y_pred - y_val)\n",
        "\n",
        "    # Mean Absolute Error (MAE) durch Bilden des Mittelwertes berechnen\n",
        "    mae = mean_absolute_error(y_val, y_pred)\n",
        "    \n",
        "    # Relativen Mean Absolute Error (MAE) durch Bilden des Mittelwertes berechnen\n",
        "    mae_rel = mae/np.mean(y_val)\n",
        "    \n",
        "    # Mean Absolut Percentage Error (MAPE) berechnen\n",
        "    mape = np.mean(abs_errors/y_val)\n",
        "    \n",
        "    # Mean Squared Error \n",
        "    mse = mean_squared_error(y_val, y_pred) \n",
        "    \n",
        "    # Root Mean Squared Error\n",
        "    rmse = np.sqrt(mse) / np.mean(y_val)\n",
        "    \n",
        "    metrics_dict = {'mae': mae,\n",
        "                    'mse': mse,\n",
        "                    'mae%': mae_rel*100,\n",
        "                    'mape%': mape*100,\n",
        "                    'rmse%': rmse*100\n",
        "                   }\n",
        "    \n",
        "    if output:\n",
        "        print('Mittelwert der wahren Label', round(np.mean(y_val), 2))\n",
        "        print('MAE', round(mae, 4))\n",
        "        print('MSE', round(mse, 4))\n",
        "        print('MAE%', mae_rel*100)\n",
        "        print('MAPE%', mape*100)\n",
        "        print('RMSE%', rmse*100)\n",
        "            \n",
        "    return y_pred, metrics_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpWbczQ4PUYN"
      },
      "source": [
        "## Aufgabe 8\n",
        "- Mit dem trainierten Entscheidungsbaum (trained_decision_tree) werden im nächsten Schritt Vorhersagen für die Validierungsmenge erstellt\n",
        "- Die Vorhersagen des Entscheidungsbaums werden innerhalb von Hilfsfunktion 3 mit den tatsächlichen Labeln der Validierungmenge verglichen\n",
        "- Verschiedene Metriken zur Bewertung der Güte der Regression können herangezogen werden, s. Vorlesung\n",
        "- Was bedeutet die einzelnen Metriken, die nach Ausführen der nächsten Zelle ausgegeben werden?\n",
        "- Ist das Prognosemodell gut?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antwort: ...."
      ],
      "metadata": {
        "id": "uyc2uSrPRrLC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsVsx3a-PUYO"
      },
      "outputs": [],
      "source": [
        "# Erzeuge mit dem Trainierten Entscheidungsbaum eine Vorhersage für das Validierungsset\n",
        "y_pred, metrics_dict = predict_with_decision_tree(trained_decision_tree, X_val, y_val, output=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oi4P5McEPUYP"
      },
      "source": [
        "## Aufgabe 9\n",
        "- Wir wollen ein gute Wahl für den Hyperparameter min_samples_split treffen.\n",
        "- Dafür gibt es Hilfsfunktion 4. Können Sie erkennen, was in der Hilfsfunktion passiert?\n",
        "- Versuchen Sie einen Kommentar zu verfassen, der die Hilfsfunktion beschreibt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQHtOhNpPUYQ"
      },
      "outputs": [],
      "source": [
        "# Hilfsfunktion 4\n",
        "def optimize_hyperparam(X_train, y_train, X_val, y_val, metric='mae%'):\n",
        "    '''\n",
        "    Hilfsfunktion zur ..... \n",
        "    \n",
        "    Inputs: \n",
        "    ...\n",
        "    ...\n",
        "   \n",
        "    Outputs:\n",
        "    ...\n",
        "    ...\n",
        "    \n",
        "    \n",
        "    ''' \n",
        "    \n",
        "    # Anzahl der Beobachtungen bestimmen, funktioniert über Zeilenanzahl von X_train.\n",
        "    number_of_samples = X_train.shape[0]\n",
        "    \n",
        "    # Noch leere Liste für Metriken erstellen, die später sukzessive gefüllt wird.\n",
        "    metrics_list = []\n",
        "    \n",
        "    # Optimalen Wert für Metrik mit großer Zahl initialisieren\n",
        "    best_metric = 100000\n",
        "    \n",
        "    ## Schleife zum Optimieren des Hyperparameters min_samples split\n",
        "    # min_samples_split wird auf Werte zwischen 2 und int(np.floor(1/5*number_of_samples)) gesetzt und in Einserschritten erhöht.\n",
        "    # Für jedes gesetzte min_samples_split wird ein Entscheidungsbaum trainiert \n",
        "    # und dessen Performance anhand der Validierungsmenge getestet\n",
        "    for min_samples_split in range(2, int(np.floor(1/3*number_of_samples))):\n",
        "        \n",
        "        # Trainieren eines Entscheidungsbaums mit bestimmtem Wert für min_samples_split \n",
        "        decision_tree = train_decision_tree(X_train, y_train, min_samples_split = min_samples_split, output=False)\n",
        "        \n",
        "        # Auswerten der Performance des Entscheidungsbaums durch Einsetzen der Validierungsmenge \n",
        "        # und Vergleich der vorhergesagten Label y_pred mit den wahren Labeln y_val\n",
        "        y_pred, metrics_dict = predict_with_decision_tree(decision_tree, X_val, y_val, output=False)\n",
        "        metrics_list.append((min_samples_split, metrics_dict))\n",
        "        \n",
        "        # Finden des optimalen Werts für min_samples_split\n",
        "        if metrics_dict[metric] <= best_metric:\n",
        "            best_metric = metrics_dict[metric]\n",
        "            best_min_split = min_samples_split \n",
        "            \n",
        "    ## Plotten der Ergebnisse \n",
        "    # Linienplot mit (x=Werte für min_samples_split, y=Wert der ausgewählten Metrik)\n",
        "    plt.figure(figsize=(20,10))\n",
        "    sns.lineplot(x=[i[0] for i in metrics_list], y=[i[1][metric] for i in metrics_list])\n",
        "    # Vertikale Linie bei x=best_min_split\n",
        "    plt.axvline(x=best_min_split, color='k', linestyle = '--')\n",
        "    # Horizontale Linie bei dazugehörigem y, sowie Legende erzeugen\n",
        "    plt.axhline(y=best_metric, color='k', linestyle = '--', \n",
        "                label='Bester Wert für min_samples_split: ' + str(best_min_split) + '\\n' + metric + ': ' + str(best_metric))\n",
        "    plt.legend()\n",
        "    \n",
        "    # Ausgabe der Funktion\n",
        "    return metrics_list, best_metric, best_min_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hifsuDSuPUYT"
      },
      "source": [
        "## Aufgabe 10\n",
        "- Führen Sie die obige Zelle aus, sodass die Funktion optimize_hyperparam() definiert wird.\n",
        "- Wenden Sie anschließend die Funktion optimize_hyperparam() an durch ausführen der unteren Zelle und bestimmen Sie metrics_list, best_metric und best_min_split\n",
        "- Wie interpretieren Sie den erzeugten Plot? Wie sollten Sie den Hyperparameter min_samples_split setzen?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjt84xzdPUYW"
      },
      "outputs": [],
      "source": [
        "metrics_list, best_metric, best_min_split = optimize_hyperparam() # in die Klammer muss noch etwas rein, was?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkf8a2APPUYW"
      },
      "source": [
        "## Aufgabe 11\n",
        "- Trainieren Sie erneut einen Entscheidungsbaum und setzten Sie dabei gezielt min_samples_split auf den gefundenen optimalen Wert, indem Sie die unten stehende Funktion ausführen.\n",
        "- Was sagen Sie zu dem Ergebnis?\n",
        "- Wenn Sie mit einem Fehler %mae <= 7% zufrieden wären, welche Werte für best_min_split könnten Sie setzen? Welchen Wert würden Sie wählen, um eine gute Interpretierbarkeit des Baumes durch den Menschen zu gewährleisten?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antwort: ...."
      ],
      "metadata": {
        "id": "QC1GnNVdRz9K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Td0xhZR3PUYX"
      },
      "outputs": [],
      "source": [
        "# Trainiere Entescheidungsbaum mit min_samples_split = best_min_split\n",
        "# best_min_split ist dabei der beste gefundene Wert für diesen Hyperparameter aus der Optimierungs oben.\n",
        "decision_tree_large = train_decision_tree(X_train, y_train, min_samples_split = best_min_split, output=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8kQhJH3PUYY"
      },
      "outputs": [],
      "source": [
        "# Trainiere einen kleineren Entscheidungsbaum durch setzen eines anderen Wertes für min_samples_split, sodass mae% vertretbar\n",
        "\n",
        "# Diese Zeile wieder einkommentieren und anpassen\n",
        "#decision_tree_smaller = train_decision_tree(X_train, y_train, min_samples_split = TODO anpassen, output=True) \n",
        "\n",
        "\n",
        "# Überprüfe Performance auf Validierungsmenge\n",
        "y_pred, metrics_dict = predict_with_decision_tree(decision_tree_smaller, X_val, y_val, output=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3rEtMj6PUYZ"
      },
      "source": [
        "## Aufgabe 12\n",
        "- Prüfen Sie die Performance des großen und des kleinen Entscheidungsbaumes auf dem Testset.\n",
        "- Wie interpretieren Sie die Ergebnisse? Wäre der kleine Entscheidungsbaum vertretbar?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antwort: ..."
      ],
      "metadata": {
        "id": "O0zkeWGMR460"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUIo3_jDPUYZ"
      },
      "outputs": [],
      "source": [
        "# Performance des großen Entscheidungsbaums auf dem Testset\n",
        "y_pred, metrics_dict = predict_with_decision_tree(decision_tree_large, X_test, y_test, output=True)\n",
        "\n",
        "# Ausgabe einer leeren Zeile für die Übersichtlichkeit\n",
        "print()\n",
        "\n",
        "# Performance des kleinen Entscheidungsbaums auf dem Testset\n",
        "y_pred, metrics_dict = predict_with_decision_tree(decision_tree_smaller, X_test, y_test, output=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FDla9YOPUYa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}